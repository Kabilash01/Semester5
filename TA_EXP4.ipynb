{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af0eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.13.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: click in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\aida-lab\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scipy scikit-learn matplotlib seaborn nltk spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41d074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter-Based Feature Selection for Text Documents\n",
      "============================================================\n",
      "Dataset: 15 documents\n",
      "Classes: {'positive', 'negative'}\n",
      "================================================================================\n",
      "COMPREHENSIVE FILTER-BASED FEATURE SELECTION COMPARISON\n",
      "================================================================================\n",
      "TF-IDF Matrix Shape: (15, 124)\n",
      "Number of features: 124\n",
      "\n",
      "Chi-Squared Test Results (Top 50 features):\n",
      " 1. great                | Score:   0.6769 | p-value: 4.1064e-01\n",
      " 2. terrible             | Score:   0.6748 | p-value: 4.1137e-01\n",
      " 3. broke                | Score:   0.6741 | p-value: 4.1163e-01\n",
      " 4. product broke        | Score:   0.6741 | p-value: 4.1163e-01\n",
      " 5. poor                 | Score:   0.6306 | p-value: 4.2713e-01\n",
      " 6. experience recommend | Score:   0.5242 | p-value: 4.6907e-01\n",
      " 7. horrible             | Score:   0.5242 | p-value: 4.6907e-01\n",
      " 8. horrible experience  | Score:   0.5242 | p-value: 4.6907e-01\n",
      " 9. recommend            | Score:   0.5242 | p-value: 4.6907e-01\n",
      "10. excellent            | Score:   0.4995 | p-value: 4.7973e-01\n",
      "\n",
      "Information Gain Results (Top 50 features):\n",
      " 1. great                | IG Score: 0.212897\n",
      " 2. broke                | IG Score: 0.163720\n",
      " 3. poor                 | IG Score: 0.163720\n",
      " 4. product broke        | IG Score: 0.163720\n",
      " 5. terrible             | IG Score: 0.163720\n",
      " 6. excellent            | IG Score: 0.133828\n",
      " 7. features             | IG Score: 0.133828\n",
      " 8. user                 | IG Score: 0.133828\n",
      " 9. awful                | IG Score: 0.077245\n",
      "10. awful service        | IG Score: 0.077245\n",
      "\n",
      "Spearman Correlation Results (Top 50 features):\n",
      " 1. great                | Correlation: 0.464281 | p-value: 8.1255e-02\n",
      " 2. broke                | Correlation: 0.418243 | p-value: 1.2079e-01\n",
      " 3. poor                 | Correlation: 0.418243 | p-value: 1.2079e-01\n",
      " 4. product broke        | Correlation: 0.418243 | p-value: 1.2079e-01\n",
      " 5. terrible             | Correlation: 0.418243 | p-value: 1.2079e-01\n",
      " 6. excellent            | Correlation: 0.365963 | p-value: 1.7976e-01\n",
      " 7. features             | Correlation: 0.365963 | p-value: 1.7976e-01\n",
      " 8. user                 | Correlation: 0.365963 | p-value: 1.7976e-01\n",
      " 9. awful                | Correlation: 0.285714 | p-value: 3.0194e-01\n",
      "10. awful service        | Correlation: 0.285714 | p-value: 3.0194e-01\n",
      "\n",
      "TF-IDF Scoring Results (Top 50 features):\n",
      " 1. product              | Mean TF-IDF: 0.062287\n",
      " 2. great                | Mean TF-IDF: 0.051577\n",
      " 3. service              | Mean TF-IDF: 0.051127\n",
      " 4. customer             | Mean TF-IDF: 0.050103\n",
      " 5. quality              | Mean TF-IDF: 0.049871\n",
      " 6. experience           | Mean TF-IDF: 0.046690\n",
      " 7. terrible             | Mean TF-IDF: 0.039365\n",
      " 8. broke                | Mean TF-IDF: 0.039321\n",
      " 9. product broke        | Mean TF-IDF: 0.039321\n",
      "10. excellent            | Mean TF-IDF: 0.038056\n",
      "\n",
      "Pearson Correlation Results (Top 50 features):\n",
      " 1. great                | Correlation: 0.467617 | p-value: 7.8805e-02\n",
      " 2. poor                 | Correlation: 0.419289 | p-value: 1.1977e-01\n",
      " 3. terrible             | Correlation: 0.418555 | p-value: 1.2049e-01\n",
      " 4. broke                | Correlation: 0.418522 | p-value: 1.2052e-01\n",
      " 5. product broke        | Correlation: 0.418522 | p-value: 1.2052e-01\n",
      " 6. excellent            | Correlation: 0.366898 | p-value: 1.7856e-01\n",
      " 7. features             | Correlation: 0.364661 | p-value: 1.8143e-01\n",
      " 8. user                 | Correlation: 0.364661 | p-value: 1.8143e-01\n",
      " 9. customer support     | Correlation: 0.285714 | p-value: 3.0194e-01\n",
      "10. disappointed         | Correlation: 0.285714 | p-value: 3.0194e-01\n",
      "\n",
      "================================================================================\n",
      "CONSENSUS FEATURES (Selected by multiple methods):\n",
      "================================================================================\n",
      " 1. great                     | Selected by 5 methods\n",
      " 2. terrible                  | Selected by 5 methods\n",
      " 3. broke                     | Selected by 5 methods\n",
      " 4. product broke             | Selected by 5 methods\n",
      " 5. poor                      | Selected by 5 methods\n",
      " 6. experience recommend      | Selected by 5 methods\n",
      " 7. horrible                  | Selected by 5 methods\n",
      " 8. horrible experience       | Selected by 5 methods\n",
      " 9. recommend                 | Selected by 5 methods\n",
      "10. excellent                 | Selected by 5 methods\n",
      "11. features                  | Selected by 5 methods\n",
      "12. user                      | Selected by 5 methods\n",
      "13. broke immediately         | Selected by 5 methods\n",
      "14. immediately               | Selected by 5 methods\n",
      "15. immediately purchase      | Selected by 5 methods\n",
      "16. purchase                  | Selected by 5 methods\n",
      "17. awful                     | Selected by 4 methods\n",
      "18. awful service             | Selected by 4 methods\n",
      "19. behavior                  | Selected by 4 methods\n",
      "20. customer support          | Selected by 4 methods\n",
      "Original matrix shape: (15, 124)\n",
      "Reduced matrix shape: (15, 20)\n",
      "Dimensionality reduction: 83.9%\n",
      "\n",
      "Reduced feature set contains 20 features:\n",
      "awful, awful service, behavior, broke, broke immediately, customer support, excellent, experience recommend, features, great...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.sparse import csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TextFeatureSelector:\n",
    "  \n",
    "    \n",
    "    def __init__(self, documents, labels):\n",
    "        self.documents = documents\n",
    "        self.labels = labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.encoded_labels = self.label_encoder.fit_transform(labels)\n",
    "        self.vectorizer = None\n",
    "        self.tfidf_matrix = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def _prepare_tfidf_matrix(self, max_features=5000, ngram_range=(1, 2)):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            ngram_range=ngram_range,\n",
    "            stop_words='english',\n",
    "            lowercase=True,\n",
    "            strip_accents='unicode'\n",
    "        )\n",
    "        \n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(self.documents)\n",
    "        self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        print(f\"TF-IDF Matrix Shape: {self.tfidf_matrix.shape}\")\n",
    "        print(f\"Number of features: {len(self.feature_names)}\")\n",
    "        \n",
    "    def chi_squared_test(self, k=100):\n",
    "        if self.tfidf_matrix is None:\n",
    "            self._prepare_tfidf_matrix()\n",
    "        \n",
    "        # Apply chi-squared test\n",
    "        chi2_scores, p_values = chi2(self.tfidf_matrix, self.encoded_labels)\n",
    "        \n",
    "        # Create feature ranking\n",
    "        feature_scores = list(zip(self.feature_names, chi2_scores, p_values))\n",
    "        feature_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select top k features\n",
    "        top_features = feature_scores[:k]\n",
    "        \n",
    "        results = {\n",
    "            'method': 'Chi-Squared Test',\n",
    "            'top_features': [(feat, score) for feat, score, _ in top_features],\n",
    "            'all_scores': feature_scores,\n",
    "            'selected_feature_names': [feat for feat, _, _ in top_features]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nChi-Squared Test Results (Top {k} features):\")\n",
    "        for i, (feature, score, p_val) in enumerate(top_features[:10]):\n",
    "            print(f\"{i+1:2d}. {feature:20s} | Score: {score:8.4f} | p-value: {p_val:.4e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def information_gain(self, k=100):\n",
    "        if self.tfidf_matrix is None:\n",
    "            self._prepare_tfidf_matrix()\n",
    "        \n",
    "        def calculate_entropy(labels):\n",
    "            \"\"\"Calculate entropy of label distribution\"\"\"\n",
    "            unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "            probabilities = counts / len(labels)\n",
    "            return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "        \n",
    "        def calculate_ig(feature_values, labels):\n",
    "            \"\"\"Calculate Information Gain for a feature\"\"\"\n",
    "            total_entropy = calculate_entropy(labels)\n",
    "            \n",
    "            # Split data based on feature presence/absence\n",
    "            feature_present = feature_values > 0\n",
    "            feature_absent = feature_values == 0\n",
    "            \n",
    "            if np.sum(feature_present) == 0 or np.sum(feature_absent) == 0:\n",
    "                return 0\n",
    "            \n",
    "            # Calculate weighted entropy\n",
    "            p_present = np.sum(feature_present) / len(labels)\n",
    "            p_absent = np.sum(feature_absent) / len(labels)\n",
    "            \n",
    "            entropy_present = calculate_entropy(labels[feature_present])\n",
    "            entropy_absent = calculate_entropy(labels[feature_absent])\n",
    "            \n",
    "            weighted_entropy = p_present * entropy_present + p_absent * entropy_absent\n",
    "            \n",
    "            return total_entropy - weighted_entropy\n",
    "        \n",
    "        # Calculate Information Gain for each feature\n",
    "        ig_scores = []\n",
    "        for i in range(self.tfidf_matrix.shape[1]):\n",
    "            feature_values = self.tfidf_matrix[:, i].toarray().flatten()\n",
    "            ig_score = calculate_ig(feature_values, self.encoded_labels)\n",
    "            ig_scores.append(ig_score)\n",
    "        \n",
    "        # Create feature ranking\n",
    "        feature_scores = list(zip(self.feature_names, ig_scores))\n",
    "        feature_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select top k features\n",
    "        top_features = feature_scores[:k]\n",
    "        \n",
    "        results = {\n",
    "            'method': 'Information Gain',\n",
    "            'top_features': top_features,\n",
    "            'all_scores': feature_scores,\n",
    "            'selected_feature_names': [feat for feat, _ in top_features]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nInformation Gain Results (Top {k} features):\")\n",
    "        for i, (feature, score) in enumerate(top_features[:10]):\n",
    "            print(f\"{i+1:2d}. {feature:20s} | IG Score: {score:8.6f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def spearman_correlation(self, k=100):\n",
    "        if self.tfidf_matrix is None:\n",
    "            self._prepare_tfidf_matrix()\n",
    "        \n",
    "        # Calculate Spearman correlation for each feature\n",
    "        correlations = []\n",
    "        p_values = []\n",
    "        \n",
    "        for i in range(self.tfidf_matrix.shape[1]):\n",
    "            feature_values = self.tfidf_matrix[:, i].toarray().flatten()\n",
    "            \n",
    "            # Handle constant features\n",
    "            if np.var(feature_values) == 0:\n",
    "                correlations.append(0)\n",
    "                p_values.append(1.0)\n",
    "            else:\n",
    "                corr, p_val = spearmanr(feature_values, self.encoded_labels)\n",
    "                correlations.append(abs(corr) if not np.isnan(corr) else 0)\n",
    "                p_values.append(p_val if not np.isnan(p_val) else 1.0)\n",
    "        \n",
    "        # Create feature ranking\n",
    "        feature_scores = list(zip(self.feature_names, correlations, p_values))\n",
    "        feature_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select top k features\n",
    "        top_features = feature_scores[:k]\n",
    "        \n",
    "        results = {\n",
    "            'method': 'Spearman Correlation',\n",
    "            'top_features': [(feat, corr) for feat, corr, _ in top_features],\n",
    "            'all_scores': feature_scores,\n",
    "            'selected_feature_names': [feat for feat, _, _ in top_features]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nSpearman Correlation Results (Top {k} features):\")\n",
    "        for i, (feature, corr, p_val) in enumerate(top_features[:10]):\n",
    "            print(f\"{i+1:2d}. {feature:20s} | Correlation: {corr:8.6f} | p-value: {p_val:.4e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def tfidf_scoring(self, k=100):\n",
    "        if self.tfidf_matrix is None:\n",
    "            self._prepare_tfidf_matrix()\n",
    "        \n",
    "        # Calculate mean TF-IDF scores\n",
    "        mean_tfidf_scores = np.array(self.tfidf_matrix.mean(axis=0)).flatten()\n",
    "        \n",
    "        # Create feature ranking\n",
    "        feature_scores = list(zip(self.feature_names, mean_tfidf_scores))\n",
    "        feature_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select top k features\n",
    "        top_features = feature_scores[:k]\n",
    "        \n",
    "        results = {\n",
    "            'method': 'TF-IDF Scoring',\n",
    "            'top_features': top_features,\n",
    "            'all_scores': feature_scores,\n",
    "            'selected_feature_names': [feat for feat, _ in top_features]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nTF-IDF Scoring Results (Top {k} features):\")\n",
    "        for i, (feature, score) in enumerate(top_features[:10]):\n",
    "            print(f\"{i+1:2d}. {feature:20s} | Mean TF-IDF: {score:8.6f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def pearson_correlation(self, k=100):\n",
    "        if self.tfidf_matrix is None:\n",
    "            self._prepare_tfidf_matrix()\n",
    "        \n",
    "        # Calculate Pearson correlation for each feature\n",
    "        correlations = []\n",
    "        p_values = []\n",
    "        \n",
    "        for i in range(self.tfidf_matrix.shape[1]):\n",
    "            feature_values = self.tfidf_matrix[:, i].toarray().flatten()\n",
    "            \n",
    "            # Handle constant features\n",
    "            if np.var(feature_values) == 0:\n",
    "                correlations.append(0)\n",
    "                p_values.append(1.0)\n",
    "            else:\n",
    "                corr, p_val = pearsonr(feature_values, self.encoded_labels)\n",
    "                correlations.append(abs(corr) if not np.isnan(corr) else 0)\n",
    "                p_values.append(p_val if not np.isnan(p_val) else 1.0)\n",
    "        \n",
    "        # Create feature ranking\n",
    "        feature_scores = list(zip(self.feature_names, correlations, p_values))\n",
    "        feature_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select top k features\n",
    "        top_features = feature_scores[:k]\n",
    "        \n",
    "        results = {\n",
    "            'method': 'Pearson Correlation',\n",
    "            'top_features': [(feat, corr) for feat, corr, _ in top_features],\n",
    "            'all_scores': feature_scores,\n",
    "            'selected_feature_names': [feat for feat, _, _ in top_features]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nPearson Correlation Results (Top {k} features):\")\n",
    "        for i, (feature, corr, p_val) in enumerate(top_features[:10]):\n",
    "            print(f\"{i+1:2d}. {feature:20s} | Correlation: {corr:8.6f} | p-value: {p_val:.4e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def compare_all_methods(self, k=100):\n",
    "        \"\"\"\n",
    "        Compare all feature selection methods\n",
    "        \n",
    "        Args:\n",
    "            k: Number of top features to select for each method\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with results from all methods\n",
    "        \"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"COMPREHENSIVE FILTER-BASED FEATURE SELECTION COMPARISON\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Run all methods\n",
    "        results['chi_squared'] = self.chi_squared_test(k)\n",
    "        results['information_gain'] = self.information_gain(k)\n",
    "        results['spearman_correlation'] = self.spearman_correlation(k)\n",
    "        results['tfidf_scoring'] = self.tfidf_scoring(k)\n",
    "        results['pearson_correlation'] = self.pearson_correlation(k)\n",
    "        \n",
    "        # Find common features across methods\n",
    "        all_selected_features = []\n",
    "        for method_results in results.values():\n",
    "            all_selected_features.extend(method_results['selected_feature_names'])\n",
    "        \n",
    "        from collections import Counter\n",
    "        feature_counts = Counter(all_selected_features)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 80)\n",
    "        print(\"CONSENSUS FEATURES (Selected by multiple methods):\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        consensus_features = [(feat, count) for feat, count in feature_counts.items() if count > 1]\n",
    "        consensus_features.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for i, (feature, count) in enumerate(consensus_features[:20]):\n",
    "            print(f\"{i+1:2d}. {feature:25s} | Selected by {count} methods\")\n",
    "        \n",
    "        results['consensus_features'] = consensus_features\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_selected_features_matrix(self, selected_features):\n",
    "        \"\"\"\n",
    "        Get TF-IDF matrix with only selected features\n",
    "        \n",
    "        Args:\n",
    "            selected_features: List of feature names to include\n",
    "            \n",
    "        Returns:\n",
    "            Reduced TF-IDF matrix and feature names\n",
    "        \"\"\"\n",
    "        if self.tfidf_matrix is None:\n",
    "            self._prepare_tfidf_matrix()\n",
    "        \n",
    "        # Find indices of selected features\n",
    "        feature_indices = [i for i, name in enumerate(self.feature_names) \n",
    "                          if name in selected_features]\n",
    "        \n",
    "        # Create reduced matrix\n",
    "        reduced_matrix = self.tfidf_matrix[:, feature_indices]\n",
    "        reduced_feature_names = [self.feature_names[i] for i in feature_indices]\n",
    "        \n",
    "        print(f\"Original matrix shape: {self.tfidf_matrix.shape}\")\n",
    "        print(f\"Reduced matrix shape: {reduced_matrix.shape}\")\n",
    "        print(f\"Dimensionality reduction: {(1 - reduced_matrix.shape[1]/self.tfidf_matrix.shape[1])*100:.1f}%\")\n",
    "        \n",
    "        return reduced_matrix, reduced_feature_names\n",
    "\n",
    "\n",
    "# Example usage and demonstration\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Demonstration of filter-based feature selection methods\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample text documents and labels\n",
    "    sample_documents = [\n",
    "        \"This is a great product with excellent quality and fast delivery\",\n",
    "        \"Poor service and terrible customer support, very disappointed\",\n",
    "        \"Amazing features and user-friendly interface, highly recommended\",\n",
    "        \"Waste of money, product broke after one day of use\",\n",
    "        \"Outstanding performance and reliable functionality\",\n",
    "        \"Horrible experience, would not recommend to anyone\",\n",
    "        \"Excellent value for money and great customer service\",\n",
    "        \"Defective item received, requesting immediate refund\",\n",
    "        \"Perfect solution for my needs, very satisfied\",\n",
    "        \"Complete disaster, poor quality and late delivery\",\n",
    "        \"Superb product quality and exceptional customer care\",\n",
    "        \"Terrible product, broke immediately after purchase\",\n",
    "        \"Fantastic features and smooth user experience\",\n",
    "        \"Awful service, unprofessional staff behavior\",\n",
    "        \"Great investment, exceeded my expectations completely\"\n",
    "    ]\n",
    "    \n",
    "    sample_labels = [\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\",\n",
    "        \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Filter-Based Feature Selection for Text Documents\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Dataset: {len(sample_documents)} documents\")\n",
    "    print(f\"Classes: {set(sample_labels)}\")\n",
    "    \n",
    "    # Initialize feature selector\n",
    "    selector = TextFeatureSelector(sample_documents, sample_labels)\n",
    "    \n",
    "    # Run comprehensive comparison\n",
    "    results = selector.compare_all_methods(k=50)\n",
    "    \n",
    "    # Example: Get reduced feature matrix using consensus features\n",
    "    if results['consensus_features']:\n",
    "        top_consensus = [feat for feat, _ in results['consensus_features'][:20]]\n",
    "        reduced_matrix, reduced_features = selector.get_selected_features_matrix(top_consensus)\n",
    "        \n",
    "        print(f\"\\nReduced feature set contains {len(reduced_features)} features:\")\n",
    "        print(\", \".join(reduced_features[:10]) + \"...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
