{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697dbe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aida-lab\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading pandas-2.3.1-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.3 MB 1.4 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.1/11.3 MB 656.4 kB/s eta 0:00:18\n",
      "   ---------------------------------------- 0.1/11.3 MB 901.1 kB/s eta 0:00:13\n",
      "    --------------------------------------- 0.2/11.3 MB 1.1 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.3/11.3 MB 1.5 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.4/11.3 MB 1.6 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.5/11.3 MB 1.6 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.6/11.3 MB 1.7 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.6/11.3 MB 1.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.7/11.3 MB 1.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/11.3 MB 1.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/11.3 MB 1.5 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.9/11.3 MB 1.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.0/11.3 MB 1.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.1/11.3 MB 1.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.2/11.3 MB 1.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.3/11.3 MB 1.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.4/11.3 MB 1.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.5/11.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.6/11.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.8/11.3 MB 1.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.9/11.3 MB 1.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.0/11.3 MB 1.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.0/11.3 MB 1.9 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.2/11.3 MB 1.9 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.3/11.3 MB 2.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.5/11.3 MB 2.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.5/11.3 MB 2.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.6/11.3 MB 2.0 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.9/11.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.2/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.3/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.5/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.6/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.8/11.3 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.9/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.0/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.0/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.1/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.2/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.2/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.4/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.5/11.3 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.5/11.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.7/11.3 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.7/11.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.8/11.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.0/11.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.1/11.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.2/11.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.3/11.3 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.5/11.3 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.7/11.3 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.0/11.3 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.3/11.3 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.7/11.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.1/11.3 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.3/11.3 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.8/11.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.2/11.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.5/11.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.9/11.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.0/11.3 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.2/11.3 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.3 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.6/11.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.9/11.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.1/11.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.3/11.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.4/11.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.6/11.3 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.8/11.3 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.2/11.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "   ---------------------------------------- 0.0/509.2 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 307.2/509.2 kB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  501.8/509.2 kB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 509.2/509.2 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "   ---------------------------------------- 0.0/347.8 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 256.0/347.8 kB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 337.9/347.8 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 347.8/347.8 kB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\aida-lab\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    " !pip install nltk pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1286ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\aida-\n",
      "[nltk_data]     lab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\aida-\n",
      "[nltk_data]     lab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aida-lab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\aida-\n",
      "[nltk_data]     lab\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e532059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The camera quality was amazing ! but battery life was not impressive and charging takes forever\n",
      "\n",
      "Processed:\n",
      "the camera quality wa amazing but battery life wa not impressive and charging take forever\n",
      "\n",
      "Batch processing:\n",
      "1. the camera quality wa amazing but battery life wa not impressive\n",
      "2. i love this product it working perfectly\n",
      "3. not good at all the quality is terrible\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Simple preprocessing: remove punctuation, tokenize, lemmatize\"\"\"\n",
    "    \n",
    "    # Initialize lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Convert to lowercase and tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()]\n",
    "    \n",
    "    # Join back to text\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Sample review\n",
    "    review = \"The camera quality was amazing ! but battery life was not impressive and charging takes forever\"\n",
    "    \n",
    "    print(\"Original:\")\n",
    "    print(review)\n",
    "    \n",
    "    print(\"\\nProcessed:\")\n",
    "    print(preprocess_text(review))\n",
    "    \n",
    "    # Multiple reviews\n",
    "    reviews = [\n",
    "        \"The camera quality was amazing ! but battery life was not impressive\",\n",
    "        \"I love this product!!! It's working perfectly\",\n",
    "        \"Not good at all. The quality is terrible\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nBatch processing:\")\n",
    "    for i, review in enumerate(reviews):\n",
    "        processed = preprocess_text(review)\n",
    "        print(f\"{i+1}. {processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef2377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(review):\n",
    "    review = review.lower()\n",
    "    review = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "    tokens = word_tokenize(review)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    return processed_tokens\n",
    "review = \"the camera quality was amazing! but battery life was not impreovise and charging takes forever\"\n",
    "processed_review_lemmatization = preprocess_review(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30446108",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_review_lemmatization = preprocess_review(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccc7b5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL REVIEWS:\n",
      "1: i absolute love this phone the display is stunning and battery life is great\n",
      "2: the sound quality is poor and design feels cheap\n",
      "3: decent product could be better in terms of speed\n",
      "\n",
      "CLEANED REVIEWS:\n",
      "1: i absolute love this phone the display is stunning and battery life is great\n",
      "2: the sound quality is poor and design feels cheap\n",
      "3: decent product could be better in terms of speed\n",
      "\n",
      "==================================================\n",
      "BAG OF WORDS\n",
      "==================================================\n",
      "Vocabulary: ['absolute', 'battery', 'better', 'cheap', 'decent', 'design', 'display', 'feels', 'great', 'life', 'love', 'phone', 'poor', 'product', 'quality', 'sound', 'speed', 'stunning', 'terms']\n",
      "\n",
      "Bag of Words Matrix:\n",
      "          absolute  battery  better  cheap  decent  design  display  feels  \\\n",
      "Review_1         1        1       0      0       0       0        1      0   \n",
      "Review_2         0        0       0      1       0       1        0      1   \n",
      "Review_3         0        0       1      0       1       0        0      0   \n",
      "\n",
      "          great  life  love  phone  poor  product  quality  sound  speed  \\\n",
      "Review_1      1     1     1      1     0        0        0      0      0   \n",
      "Review_2      0     0     0      0     1        0        1      1      0   \n",
      "Review_3      0     0     0      0     0        1        0      0      1   \n",
      "\n",
      "          stunning  terms  \n",
      "Review_1         1      0  \n",
      "Review_2         0      0  \n",
      "Review_3         0      1  \n",
      "Shape: (3, 19)\n",
      "\n",
      "==================================================\n",
      "N-GRAMS (BIGRAMS)\n",
      "==================================================\n",
      "N-gram Features (1-gram + 2-gram):\n",
      "['absolute', 'absolute love', 'battery', 'battery life', 'better', 'better terms', 'cheap', 'decent', 'decent product', 'design', 'design feels', 'display', 'display stunning', 'feels', 'feels cheap', 'great', 'life', 'life great', 'love', 'love phone', 'phone', 'phone display', 'poor', 'poor design', 'product', 'product better', 'quality', 'quality poor', 'sound', 'sound quality', 'speed', 'stunning', 'stunning battery', 'terms', 'terms speed']\n",
      "\n",
      "N-gram Matrix Shape: (3, 35)\n",
      "\n",
      "First few columns:\n",
      "          absolute  absolute love  battery  battery life  better  \\\n",
      "Review_1         1              1        1             1       0   \n",
      "Review_2         0              0        0             0       0   \n",
      "Review_3         0              0        0             0       1   \n",
      "\n",
      "          better terms  cheap  decent  decent product  design  \n",
      "Review_1             0      0       0               0       0  \n",
      "Review_2             0      1       0               0       1  \n",
      "Review_3             1      0       1               1       0  \n",
      "\n",
      "==================================================\n",
      "TF-IDF\n",
      "==================================================\n",
      "TF-IDF Matrix:\n",
      "          absolute  battery  better  cheap  decent  design  display  feels  \\\n",
      "Review_1     0.354    0.354   0.000  0.000   0.000   0.000    0.354  0.000   \n",
      "Review_2     0.000    0.000   0.000  0.408   0.000   0.408    0.000  0.408   \n",
      "Review_3     0.000    0.000   0.447  0.000   0.447   0.000    0.000  0.000   \n",
      "\n",
      "          great   life   love  phone   poor  product  quality  sound  speed  \\\n",
      "Review_1  0.354  0.354  0.354  0.354  0.000    0.000    0.000  0.000  0.000   \n",
      "Review_2  0.000  0.000  0.000  0.000  0.408    0.000    0.408  0.408  0.000   \n",
      "Review_3  0.000  0.000  0.000  0.000  0.000    0.447    0.000  0.000  0.447   \n",
      "\n",
      "          stunning  terms  \n",
      "Review_1     0.354  0.000  \n",
      "Review_2     0.000  0.000  \n",
      "Review_3     0.000  0.447  \n",
      "Shape: (3, 19)\n",
      "\n",
      "==================================================\n",
      "FINAL NUMERICAL FEATURES\n",
      "==================================================\n",
      "Final feature matrix shape: (3, 19)\n",
      "Number of reviews: 3\n",
      "Number of features per review: 19\n",
      "\n",
      "Final numerical matrix:\n",
      "[[0.354 0.354 0.    0.    0.    0.    0.354 0.    0.354 0.354 0.354 0.354\n",
      "  0.    0.    0.    0.    0.    0.354 0.   ]\n",
      " [0.    0.    0.    0.408 0.    0.408 0.    0.408 0.    0.    0.    0.\n",
      "  0.408 0.    0.408 0.408 0.    0.    0.   ]\n",
      " [0.    0.    0.447 0.    0.447 0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.447 0.    0.    0.447 0.    0.447]]\n",
      "\n",
      " SUCCESS: Text converted to 19 numerical features!\n",
      "This matrix is ready for machine learning algorithms.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "\n",
    "# Your sample data\n",
    "reviews = [\n",
    "    \"i absolute love this phone the display is stunning and battery life is great\",\n",
    "    \"the sound quality is poor and design feels cheap\", \n",
    "    \"decent product could be better in terms of speed\"\n",
    "]\n",
    "\n",
    "print(\"ORIGINAL REVIEWS:\")\n",
    "for i, review in enumerate(reviews, 1):\n",
    "    print(f\"{i}: {review}\")\n",
    "\n",
    "# Step 1: Simple Text Cleaning\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove numbers and special characters\n",
    "    text = ' '.join(text.split())  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "cleaned_reviews = [clean_text(review) for review in reviews]\n",
    "\n",
    "print(\"\\nCLEANED REVIEWS:\")\n",
    "for i, review in enumerate(cleaned_reviews, 1):\n",
    "    print(f\"{i}: {review}\")\n",
    "\n",
    "# Step 2: Bag of Words\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BAG OF WORDS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "bow_matrix = bow_vectorizer.fit_transform(cleaned_reviews)\n",
    "\n",
    "# Convert to readable format\n",
    "bow_df = pd.DataFrame(\n",
    "    bow_matrix.toarray(),\n",
    "    columns=bow_vectorizer.get_feature_names_out(),\n",
    "    index=[f'Review_{i+1}' for i in range(len(reviews))]\n",
    ")\n",
    "\n",
    "print(\"Vocabulary:\", list(bow_vectorizer.get_feature_names_out()))\n",
    "print(\"\\nBag of Words Matrix:\")\n",
    "print(bow_df)\n",
    "print(f\"Shape: {bow_df.shape}\")\n",
    "\n",
    "# Step 3: N-grams (Bigrams)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"N-GRAMS (BIGRAMS)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "ngram_matrix = ngram_vectorizer.fit_transform(cleaned_reviews)\n",
    "\n",
    "ngram_df = pd.DataFrame(\n",
    "    ngram_matrix.toarray(),\n",
    "    columns=ngram_vectorizer.get_feature_names_out(),\n",
    "    index=[f'Review_{i+1}' for i in range(len(reviews))]\n",
    ")\n",
    "\n",
    "print(\"N-gram Features (1-gram + 2-gram):\")\n",
    "print(list(ngram_vectorizer.get_feature_names_out()))\n",
    "print(f\"\\nN-gram Matrix Shape: {ngram_df.shape}\")\n",
    "print(\"\\nFirst few columns:\")\n",
    "print(ngram_df.iloc[:, :10])  # Show first 10 features\n",
    "\n",
    "# Step 4: TF-IDF\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TF-IDF\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(cleaned_reviews)\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_vectorizer.get_feature_names_out(),\n",
    "    index=[f'Review_{i+1}' for i in range(len(reviews))]\n",
    ")\n",
    "\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_df.round(3))\n",
    "print(f\"Shape: {tfidf_df.shape}\")\n",
    "\n",
    "# Step 5: Final Numerical Features (Ready to use)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL NUMERICAL FEATURES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Choose TF-IDF as final features (you can choose any method above)\n",
    "final_features = tfidf_matrix.toarray()\n",
    "\n",
    "print(f\"Final feature matrix shape: {final_features.shape}\")\n",
    "print(f\"Number of reviews: {final_features.shape[0]}\")\n",
    "print(f\"Number of features per review: {final_features.shape[1]}\")\n",
    "\n",
    "print(\"\\nFinal numerical matrix:\")\n",
    "print(final_features.round(3))\n",
    "\n",
    "print(f\"\\n SUCCESS: Text converted to {final_features.shape[1]} numerical features!\")\n",
    "print(\"This matrix is ready for machine learning algorithms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b29f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
